Instructions for the project:
These are all the commands that you need to run on your command prompt

Write Python in your terminal
If you have Python, then no need to install it
 uv --version
If you are not able to get the version
Pip install uv
import shutil
print(shutil.which("uv"))
 
 6. Uv init <my-project-name>
7. uv pip list
 
8. uv python list
uv venv env --python cpython-3.10.18-windows-x86_64-none
uv venv <your-env-namne> --python <your-python-version>
Note: Please use either 3.10, 3.11, or 3.12
Command Prompt (CMD)  .\<your-env-nanme>\Scripts\activate.bat
Git Bash ya WSL terminal, or MAC Terminal:
source <your-env-nanme>/Scripts/activate


18. If your git is asking for a login to publish the repo, execute the command below
git config --global user.name "Your Name"
git config --global user.email "your-email@example.com"
19. UV add <package_name>
20. Uv add -r requirements.txt
21. Streamlit run <give your streamlit python filename>
22. Install the live server extension in VS Code for testing the HTML

For accessing the DataStax, here is a link: https://accounts.datastax.com/session-service/v1/login

Vectordb Comparison: https://superlinked.com/vector-db-comparison

Login to DataStax for astradb vector-> create a database fill the details: 1) database name 2) select AWS 3) select region 
Now when the database become active copy the following details for .env: 1) API endpoint 2) Generate Token and copy it 3) default keyspace

#########################################################################################################################
                                    PROJECT DESCRIPTION

ELT(Extract load transform) Pipeline:
    step 1: scrappe the data from website.
    step 2: store the data in vectorDB. here it is AstraDB

    We will scrapp the data from the website, then we will parse html using beautiful soul this step is extract.
    Ten load the data into csv writer. next transform the data in to Document using langchain document to store 
    the embeddings in vector DB.

    Tech:
    1) BS4(beautiful soup)-> use for HTML parsing
    2) Selenium -> Browser level scrapping